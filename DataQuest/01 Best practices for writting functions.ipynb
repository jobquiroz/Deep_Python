{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tested-double",
   "metadata": {},
   "source": [
    "## Introducing docstrings\n",
    "\n",
    "In this mission, we'll cover some best practices that will make your code much easier to use, read, and maintain, including:\n",
    "\n",
    "- How to document your code so that others can easily understand it.\n",
    "- How to create functions that are easier to test, debug, and change.\n",
    "- How to setup default arguments in functions so that your code doesn't behave unexpectedly.\n",
    "\n",
    "Let's start by looking at this split_and_stack() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dirty-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_stack(df, new_names):\n",
    "    half = int(len(df.columns) / 2)\n",
    "    left = df.iloc[:, :half]\n",
    "    right = df.iloc[:, half:]\n",
    "    return pd.DataFrame(data=np.vstack([left.values, right.values]), columns=new_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-couple",
   "metadata": {},
   "source": [
    "If we wanted to understand what the function does, what the arguments are supposed to be, and what it returns, we would have to spend some time deciphering the code.\n",
    "\n",
    "With a **docstring** though, it is much easier to tell what the expected inputs and outputs should be, as well as what the function does. A docstring is a string written as the first line of a function. Because docstrings usually span multiple lines, they are enclosed in triple quotes, Python's way of writing multi-line strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fitting-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_stack(df, new_names):\n",
    "    \"\"\"Splits a DataFrame's columns into two halves and then stack\n",
    "    them vertically, returning a new DataFrame with `new_names` as the\n",
    "    column names.\n",
    "\n",
    "    Args:\n",
    "      df (DataFrame): The DataFrame to split.\n",
    "      new_names (iterable of str): The column names for the new DataFrame.\n",
    "\n",
    "    Returns:\n",
    "      DataFrame\n",
    "    \"\"\"\n",
    "    half = int(len(df.columns) / 2)\n",
    "    left = df.iloc[:, :half]\n",
    "    right = df.iloc[:, half:]\n",
    "    return pd.DataFrame(\n",
    "      data=np.vstack([left.values, right.values]),\n",
    "      columns=new_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-rendering",
   "metadata": {},
   "source": [
    "Every docstring has some (although usually not all) of these five key pieces of information:\n",
    "\n",
    "- Description of what the function does.\n",
    "- Description of the arguments, if any.\n",
    "- Description of the return value(s), if any.\n",
    "- Description of errors raised, if any.\n",
    "- Optional extra notes or examples of usage.\n",
    "\n",
    "Docstrings makes it easier for you and other data scientists or engineers to use, read, and maintain your code in the future. Remember that even though computers execute it, code is actually written for humans to read (otherwise you'd just be writing the 1s and 0s that the computer operates on)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-steal",
   "metadata": {},
   "source": [
    "### Retrieving docstrings\n",
    "\n",
    "Every function in Python comes with a __doc__ attribute that holds the contents of the function's docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strange-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_answer():\n",
    "    \"\"\"Returns the answer to life, \n",
    "    the universe, and everything.\n",
    "\n",
    "    Returns:\n",
    "        int\n",
    "    \"\"\"\n",
    "    return 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parallel-prison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns the answer to life, \n",
      "    the universe, and everything.\n",
      "\n",
      "    Returns:\n",
      "        int\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(the_answer.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-novel",
   "metadata": {},
   "source": [
    "Notice that the __doc__ attribute contains the raw docstring, including any tabs or spaces that were added to make the words visually line up.\n",
    "\n",
    "To get a cleaner version, with those leading spaces removed, we can use the getdoc() function from the inspect module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sacred-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns the answer to life, \n",
      "the universe, and everything.\n",
      "\n",
      "Returns:\n",
      "    int\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print(inspect.getdoc(the_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-stadium",
   "metadata": {},
   "source": [
    "The inspect module contains a lot of useful methods for gathering information about functions, so we recommend you take some time at the end of this mission to read through the documentation.\n",
    "\n",
    "In Jupyter notebook, there's also a keyboard shortcut we can use to access the docstrings for built-in functions - just press `Shift` + `Tab` while the cursor is within the parentheses of a built-in function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-responsibility",
   "metadata": {},
   "source": [
    "### Google style docstrings\n",
    "\n",
    "Now that we know how to retrieve a function's docstring, let's learn how to write our own.\n",
    "\n",
    "Consistent style makes a project easier to read, and the Python community has evolved several standards for how to format docstrings. Google style and Numpydoc are the most popular formats. However, since Numpydoc takes up more vertical space, we'll focus on Google style in this mission to keep the examples compact and legible.\n",
    "\n",
    "#### Description of what the function does\n",
    "\n",
    "In Google style, the docstring starts with a concise description of what the function does. This should be in **imperative language**. For instance, we would write \"Split the data frame and stack the columns\" instead of \"This function will split the data frame and stack the columns.\"\n",
    "\n",
    "```\n",
    "def function(arg_1, arg_2=42):\n",
    "    \"\"\"Description of what the function does.\n",
    "    \"\"\"\n",
    "```    \n",
    "   \n",
    "#### Description of the arguments, if any\n",
    "\n",
    "Next comes the \"Args\" section where you list each argument name, followed by its expected type in parentheses, and then its role in the function. If you need extra space, break to the next line and indent, like below. If an argument has a default value, mark it as \"optional\" when describing the type. If the function does not take any parameters, leave this section out.\n",
    "\n",
    "```\n",
    "def function(arg_1, arg_2=42):\n",
    "    \"\"\"Description of what the function does.\n",
    "    Args:\n",
    "      arg_1 (str): Description of arg_1 that can break onto the next line\n",
    "        if needed.\n",
    "      arg_2 (int, optional): Write optional when an argument has a default\n",
    "        value.\n",
    "  \"\"\"\n",
    "```\n",
    "  \n",
    "#### Description of the return value(s), if any\n",
    "\n",
    "The next section is the \"Returns\" section, where you list the expected type or types of what gets returned. You can also provide some comment about what gets returned, but often the name of the function and the description will make this clear. Additional lines should not be indented.\n",
    "\n",
    "```\n",
    "def function(arg_1, arg_2=42):\n",
    "    \"\"\"Description of what the function does.\n",
    "    \n",
    "    Args:\n",
    "      arg_1 (str): Description of arg_1 that can break onto the next line\n",
    "        if needed.\n",
    "      arg_2 (int, optional): Write optional when an argument has a default\n",
    "        value.\n",
    "        \n",
    "    Returns:\n",
    "      bool: Optional description of the return value\n",
    "      Extra lines are not indented.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "#### Description of errors raised, if any.\n",
    "#### Optional extra notes or examples of usage.\n",
    "\n",
    "```\n",
    "def function(arg_1, arg_2=42):\n",
    "    \"\"\"Description of what the function does.\n",
    "\n",
    "    Args:\n",
    "      arg_1 (str): Description of arg_1 that can break onto the next line\n",
    "        if needed.\n",
    "      arg_2 (int, optional): Write optional when an argument has a default\n",
    "        value.\n",
    "\n",
    "    Returns:\n",
    "      bool: Optional description of the return value\n",
    "      Extra lines are not indented.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: Include any error types that the function intentionally\n",
    "        raises.\n",
    "\n",
    "    Notes:\n",
    "      See https://www.dataquest.io for more info.  \n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-theta",
   "metadata": {},
   "source": [
    "## Don't repeat yourself\n",
    "\n",
    "Now that we know how to make our functions easier to understand, let's look at how we can also make them easier to test, debug, and change. The **Don't repeat yourself** principle, also known as **DRY**, and the **Do One Thing** principle are good ways to ensure that our functions are well designed and easy to test. Let's see how, starting with DRY.\n",
    "\n",
    "When we write code to look for answers to a research question, it is totally normal to copy and paste a bit of code, tweak it slightly, and re-run it. However this, kind of repeated code can lead to real problems.\n",
    "\n",
    "In this code snippet, we load our train, validation, and test data, and plot the first two principal components of each dataset. Suppose we wrote the code for the train dataset, then copied it and pasted it into the next two blocks, updating the paths and the variable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train_y = train['labels'].values\n",
    "train_X = train[col for col in train.columns if col != 'labels'].values\n",
    "train_pca = PCA(n_components=2).fit_transform(train_X)\n",
    "plt.scatter(train_pca[:,0], train_pca[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv('validation.csv')\n",
    "val_y = val['labels'].values\n",
    "val_X = train[col for col in val.columns if col != 'labels'].values\n",
    "val_pca = PCA(n_components=2).fit_transform(val_X)\n",
    "plt.scatter(val_pca[:,0], val_pca[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test_y = test['labels'].values\n",
    "test_X = test[col for col in test.columns if col != 'labels'].values\n",
    "test_pca = PCA(n_components=2).fit_transform(train_X)\n",
    "plt.scatter(test_pca[:,0], test_pca[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-northwest",
   "metadata": {},
   "source": [
    "But one of the problems with copying and pasting is that it is easy to accidentally introduce errors that are hard to spot. Notice in the last block, we accidentally took the principal components of the train data instead of the test data. Yikes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test_y = test['labels'].values\n",
    "test_X = test[col for col in test.columns if col != 'labels'].values\n",
    "test_pca = PCA(n_components=2).fit_transform(train_X)  ### yikes! ###\n",
    "plt.scatter(test_pca[:,0], test_pca[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-teddy",
   "metadata": {},
   "source": [
    "Another problem with repeated code is that if we want to change something, we often have to do it in multiple places. For instance, if we realized that our CSVs used the column name \"label\" instead of \"labels,\" we would have to change our code in six places. Repeated code like this is a good sign that we should write a function.\n",
    "\n",
    "Wrapping the repeated logic in a function and then calling that function several times makes it much easier to avoid the kind of errors introduced by copying and pasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_plot(path):\n",
    "    \"\"\"Loads a data set and plot the first two principal components.\n",
    "\n",
    "    Args:\n",
    "      path (str): The location of a CSV file.\n",
    "\n",
    "    Returns:\n",
    "      tuple of ndarray: (features, labels)\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path)\n",
    "    y = data['label'].values\n",
    "    X = data[col for col in train.columns if col != 'label'].values\n",
    "    pca = PCA(n_components=2).fit_transform(X)\n",
    "    plt.scatter(pca[:,0], pca[:,1])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = load_and_plot('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X, val_y = load_and_plot('validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = load_and_plot('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-philadelphia",
   "metadata": {},
   "source": [
    "### Do One thing\n",
    "\n",
    "On the last screen, we wrapped repeated logic from our code in the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_plot(path):\n",
    "    \"\"\"Loads a data set and plot the first two principal components.\n",
    "\n",
    "    Args:\n",
    "      path (str): The location of a CSV file.\n",
    "\n",
    "    Returns:\n",
    "      tuple of ndarray: (features, labels)\n",
    "    \"\"\"\n",
    "    # load the data\n",
    "    data = pd.read_csv(path)\n",
    "    y = data['label'].values\n",
    "    X = data[col for col in train.columns if col != 'label'].values\n",
    "\n",
    "    # plot the first two principal components\n",
    "    pca = PCA(n_components=2).fit_transform(X)\n",
    "    plt.scatter(pca[:,0], pca[:,1])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-premises",
   "metadata": {},
   "source": [
    "However, there is still a big problem with this function. First, it loads the data. Then, it plots the data. And then it returns the loaded data.\n",
    "\n",
    "This function violates another software engineering principle: **Do One Thing**. Every function should have a single responsibility. Let's look at how we could split this one up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distant-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Loads a data set.\n",
    "\n",
    "    Args:\n",
    "      path (str): The location of a CSV file.\n",
    "\n",
    "    Returns:\n",
    "      tuple of ndarray: (features, labels)\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path)\n",
    "    y = data['labels'].values\n",
    "    X = data[col for col in data.columns if col != 'labels'].values\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X):\n",
    "    \"\"\"Plots the first two principal components of a matrix.\n",
    "\n",
    "    Args:\n",
    "      X (numpy.ndarray): The data to plot.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=2).fit_transform(X)\n",
    "    plt.scatter(pca[:,0], pca[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-hearts",
   "metadata": {},
   "source": [
    "Instead of one big function, we could have a more nimble function that just loads the data and a second one for plotting.\n",
    "\n",
    "We get several advantages from splitting the load_and_plot() function into two smaller functions. Our code becomes:\n",
    "\n",
    "- More flexible\n",
    "- More easily understood\n",
    "- Simpler to test\n",
    "- Simpler to debug\n",
    "- Easier to change\n",
    "\n",
    "First of all, our code has become more flexible. Imagine that later on in our script, we just want to load the data and not plot it. That's easy now with the load_data() function.\n",
    "\n",
    "Likewise, if we wanted to do some transformation to the data before plotting, we can do the transformation and then call the plot_data() function. We have decoupled the loading functionality from the plotting functionality.\n",
    "\n",
    "The code will also be easier for other developers to understand, and it will be more pleasant to test and debug.\n",
    "\n",
    "Finally, if we ever need to update our code, functions that each have a single responsibility make it easier to predict how changes in one place will affect the rest of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-dinner",
   "metadata": {},
   "source": [
    "### Pass by Assignment\n",
    "\n",
    "Another important thing to keep in mind when writing functions is that the way that Python passes information to functions is different from many other languages. It is referred to as pass by assignment.\n",
    "\n",
    "Let's say we have a function foo() that takes a list and sets the first value of the list to 99:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "removed-supplement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x):\n",
    "    x[0] = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-standard",
   "metadata": {},
   "source": [
    "Then we set my_list to the value [1, 2, 3] and pass it to foo(). What do you expect the value of my_list to be after calling foo()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "located-vegetation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99, 2, 3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [1, 2, 3]\n",
    "\n",
    "foo(my_list)\n",
    "\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-rebate",
   "metadata": {},
   "source": [
    "If you said [99, 2, 3], then you are right. Lists in Python are mutable objects, meaning that they can be changed.\n",
    "\n",
    "Now let's say we have another function bar() that takes an argument and adds 90 to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conscious-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar(x):\n",
    "    x = x + 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-commitment",
   "metadata": {},
   "source": [
    "Then we assign the value 3 to the variable my_var and call bar() with my_var as the argument. What do you expect the value of my_var to be after we call bar()?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adequate-johnson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "my_var = 3\n",
    "\n",
    "bar(my_var)\n",
    "print(my_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-kentucky",
   "metadata": {},
   "source": [
    "If you said 3, you're right. In Python, integers are immutable, meaning they can't be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-height",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-probability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
